{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e020ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd\n",
    "from io import StringIO, BytesIO\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "from sagemaker.serializers import CSVSerializer, IdentitySerializer\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2385b9",
   "metadata": {},
   "source": [
    "# Train RGCN model using SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67c29f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = \"sagemaker/ieee-fraud-detection-train\"\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cebc25b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### upload training data to S3\n",
    "inputs = sagemaker_session.upload_data(path=\"./data/train.parquet\", bucket=bucket, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d161e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create SageMaker's PyTorch estimator with custom training script\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"smtrain.py\",\n",
    "    role=role,\n",
    "    py_version=\"py38\",\n",
    "    framework_version=\"1.11.0\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.4xlarge\",\n",
    "    source_dir='fgnn',\n",
    "    volume_size=100,\n",
    "    hyperparameters={\n",
    "        'embedding_size': 64,\n",
    "        'n_layers': 2,\n",
    "        'n_epochs': 150,\n",
    "        'n_hidden': 16,\n",
    "        'dropout': 0.2,\n",
    "        'weight_decay': 5e-05,\n",
    "        'lr': 0.01,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "903d7848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-25 17:39:51 Starting - Starting the training job...\n",
      "2023-01-25 17:40:19 Starting - Preparing the instances for trainingProfilerReport-1674668390: InProgress\n",
      "......\n",
      "2023-01-25 17:41:19 Downloading - Downloading input data...\n",
      "2023-01-25 17:41:40 Training - Downloading the training image...\n",
      "2023-01-25 17:42:20 Training - Training image download completed. Training in progress.....\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:45,997 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:45,998 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:46,000 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:46,010 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:46,013 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:46,225 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 1)) (1.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: dgl in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (0.8.0.post2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (10.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (2022.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.20.3 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 1)) (1.22.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from dgl->-r requirements.txt (line 2)) (1.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx>=2.1 in /opt/conda/lib/python3.8/site-packages (from dgl->-r requirements.txt (line 2)) (2.8.8)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.8/site-packages (from dgl->-r requirements.txt (line 2)) (2.28.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from dgl->-r requirements.txt (line 2)) (4.64.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->-r requirements.txt (line 1)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->dgl->-r requirements.txt (line 2)) (2022.12.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->dgl->-r requirements.txt (line 2)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->dgl->-r requirements.txt (line 2)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests>=2.19.0->dgl->-r requirements.txt (line 2)) (1.26.13)\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:47,442 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:47,442 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:47,445 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:47,448 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:47,461 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:47,463 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:47,475 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:47,478 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:47,490 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.m5.4xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"dropout\": 0.2,\n",
      "        \"embedding_size\": 64,\n",
      "        \"lr\": 0.01,\n",
      "        \"n_epochs\": 150,\n",
      "        \"n_hidden\": 16,\n",
      "        \"n_layers\": 2,\n",
      "        \"weight_decay\": 5e-05\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.m5.4xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"job_name\": \"pytorch-training-2023-01-25-17-39-50-631\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-662565182368/pytorch-training-2023-01-25-17-39-50-631/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"smtrain\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 0,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m5.4xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m5.4xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"smtrain.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"dropout\":0.2,\"embedding_size\":64,\"lr\":0.01,\"n_epochs\":150,\"n_hidden\":16,\"n_layers\":2,\"weight_decay\":5e-05}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=smtrain.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.m5.4xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=smtrain\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-662565182368/pytorch-training-2023-01-25-17-39-50-631/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.m5.4xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"dropout\":0.2,\"embedding_size\":64,\"lr\":0.01,\"n_epochs\":150,\"n_hidden\":16,\"n_layers\":2,\"weight_decay\":5e-05},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"job_name\":\"pytorch-training-2023-01-25-17-39-50-631\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-662565182368/pytorch-training-2023-01-25-17-39-50-631/source/sourcedir.tar.gz\",\"module_name\":\"smtrain\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":0,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m5.4xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m5.4xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"smtrain.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--dropout\",\"0.2\",\"--embedding_size\",\"64\",\"--lr\",\"0.01\",\"--n_epochs\",\"150\",\"--n_hidden\",\"16\",\"--n_layers\",\"2\",\"--weight_decay\",\"5e-05\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_DROPOUT=0.2\u001b[0m\n",
      "\u001b[34mSM_HP_EMBEDDING_SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_LR=0.01\u001b[0m\n",
      "\u001b[34mSM_HP_N_EPOCHS=150\u001b[0m\n",
      "\u001b[34mSM_HP_N_HIDDEN=16\u001b[0m\n",
      "\u001b[34mSM_HP_N_LAYERS=2\u001b[0m\n",
      "\u001b[34mSM_HP_WEIGHT_DECAY=5e-05\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.22b20230106-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 smtrain.py --dropout 0.2 --embedding_size 64 --lr 0.01 --n_epochs 150 --n_hidden 16 --n_layers 2 --weight_decay 5e-05\u001b[0m\n",
      "\u001b[34m2023-01-25 12:42:47,997 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: invalid value encountered in log10\n",
      "  result = func(self.values, **kwargs)\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.8/site-packages/pandas/core/internals/blocks.py:351: RuntimeWarning: invalid value encountered in log10\n",
      "  result = func(self.values, **kwargs)\u001b[0m\n",
      "\u001b[34mConstructed heterograph with the following metagraph structure: Node types ['P_emaildomain', 'ProductCD', 'R_emaildomain', 'addr1', 'addr2', 'card1', 'card2', 'card3', 'card4', 'card5', 'card6', 'target'], Edge types[('P_emaildomain', 'P_emaildomain<>target', 'target'), ('ProductCD', 'ProductCD<>target', 'target'), ('R_emaildomain', 'R_emaildomain<>target', 'target'), ('addr1', 'addr1<>target', 'target'), ('addr2', 'addr2<>target', 'target'), ('card1', 'card1<>target', 'target'), ('card2', 'card2<>target', 'target'), ('card3', 'card3<>target', 'target'), ('card4', 'card4<>target', 'target'), ('card5', 'card5<>target', 'target'), ('card6', 'card6<>target', 'target'), ('target', 'self_relation', 'target'), ('target', 'target<>P_emaildomain', 'P_emaildomain'), ('target', 'target<>ProductCD', 'ProductCD'), ('target', 'target<>R_emaildomain', 'R_emaildomain'), ('target', 'target<>addr1', 'addr1'), ('target', 'target<>addr2', 'addr2'), ('target', 'target<>card1', 'card1'), ('target', 'target<>card2', 'card2'), ('target', 'target<>card3', 'card3'), ('target', 'target<>card4', 'card4'), ('target', 'target<>card5', 'card5'), ('target', 'target<>card6', 'card6')]\u001b[0m\n",
      "\u001b[34mNumber of nodes of type target : 115386\u001b[0m\n",
      "\u001b[34mInitialized Model\u001b[0m\n",
      "\u001b[34mStarting Model training\u001b[0m\n",
      "\u001b[34mEpoch 00000 | Time(s) 3.1458 | Loss 0.5074 | f1 0.0074\u001b[0m\n",
      "\u001b[34mEpoch 00001 | Time(s) 3.0759 | Loss 0.7101 | f1 0.4672\u001b[0m\n",
      "\u001b[34mEpoch 00002 | Time(s) 3.1978 | Loss 0.2150 | f1 0.5390\u001b[0m\n",
      "\u001b[34mEpoch 00003 | Time(s) 3.4029 | Loss 0.2142 | f1 0.3225\u001b[0m\n",
      "\u001b[34mEpoch 00004 | Time(s) 3.3261 | Loss 0.2532 | f1 0.3693\u001b[0m\n",
      "\u001b[34mEpoch 00005 | Time(s) 3.2647 | Loss 0.2549 | f1 0.5896\u001b[0m\n",
      "\u001b[34mEpoch 00006 | Time(s) 3.2283 | Loss 0.1623 | f1 0.4674\u001b[0m\n",
      "\u001b[34mEpoch 00007 | Time(s) 3.1924 | Loss 0.3309 | f1 0.5312\u001b[0m\n",
      "\u001b[34mEpoch 00008 | Time(s) 3.1649 | Loss 0.1799 | f1 0.3570\u001b[0m\n",
      "\u001b[34mEpoch 00009 | Time(s) 3.1469 | Loss 0.2863 | f1 0.3498\u001b[0m\n",
      "\u001b[34mEpoch 00010 | Time(s) 3.1318 | Loss 0.2981 | f1 0.4655\u001b[0m\n",
      "\u001b[34mEpoch 00011 | Time(s) 3.1212 | Loss 0.2380 | f1 0.5904\u001b[0m\n",
      "\u001b[34mEpoch 00012 | Time(s) 3.1098 | Loss 0.1722 | f1 0.6168\u001b[0m\n",
      "\u001b[34mEpoch 00013 | Time(s) 3.1098 | Loss 0.1678 | f1 0.6338\u001b[0m\n",
      "\u001b[34mEpoch 00014 | Time(s) 3.1227 | Loss 0.1955 | f1 0.6609\u001b[0m\n",
      "\u001b[34mEpoch 00015 | Time(s) 3.1122 | Loss 0.1703 | f1 0.6439\u001b[0m\n",
      "\u001b[34mEpoch 00016 | Time(s) 3.1025 | Loss 0.1296 | f1 0.5822\u001b[0m\n",
      "\u001b[34mEpoch 00017 | Time(s) 3.0941 | Loss 0.1469 | f1 0.5519\u001b[0m\n",
      "\u001b[34mEpoch 00018 | Time(s) 3.0861 | Loss 0.1620 | f1 0.5666\u001b[0m\n",
      "\u001b[34mEpoch 00019 | Time(s) 3.0810 | Loss 0.1584 | f1 0.6128\u001b[0m\n",
      "\u001b[34mEpoch 00020 | Time(s) 3.0761 | Loss 0.1421 | f1 0.6652\u001b[0m\n",
      "\u001b[34mEpoch 00021 | Time(s) 3.0705 | Loss 0.1273 | f1 0.6954\u001b[0m\n",
      "\u001b[34mEpoch 00022 | Time(s) 3.0662 | Loss 0.1247 | f1 0.7070\u001b[0m\n",
      "\u001b[34mEpoch 00023 | Time(s) 3.0617 | Loss 0.1301 | f1 0.7096\u001b[0m\n",
      "\u001b[34mEpoch 00024 | Time(s) 3.0585 | Loss 0.1315 | f1 0.7058\u001b[0m\n",
      "\u001b[34mEpoch 00025 | Time(s) 3.0543 | Loss 0.1230 | f1 0.6905\u001b[0m\n",
      "\u001b[34mEpoch 00026 | Time(s) 3.0504 | Loss 0.1152 | f1 0.6575\u001b[0m\n",
      "\u001b[34mEpoch 00027 | Time(s) 3.0466 | Loss 0.1160 | f1 0.6382\u001b[0m\n",
      "\u001b[34mEpoch 00028 | Time(s) 3.0434 | Loss 0.1191 | f1 0.6426\u001b[0m\n",
      "\u001b[34mEpoch 00029 | Time(s) 3.0394 | Loss 0.1188 | f1 0.6682\u001b[0m\n",
      "\u001b[34mEpoch 00030 | Time(s) 3.0500 | Loss 0.1152 | f1 0.6981\u001b[0m\n",
      "\u001b[34mEpoch 00031 | Time(s) 3.0468 | Loss 0.1117 | f1 0.7172\u001b[0m\n",
      "\u001b[34mEpoch 00032 | Time(s) 3.0440 | Loss 0.1102 | f1 0.7335\u001b[0m\n",
      "\u001b[34mEpoch 00033 | Time(s) 3.0428 | Loss 0.1092 | f1 0.7413\u001b[0m\n",
      "\u001b[34mEpoch 00034 | Time(s) 3.0399 | Loss 0.1080 | f1 0.7391\u001b[0m\n",
      "\u001b[34mEpoch 00035 | Time(s) 3.0374 | Loss 0.1072 | f1 0.7320\u001b[0m\n",
      "\u001b[34mEpoch 00036 | Time(s) 3.0358 | Loss 0.1058 | f1 0.7203\u001b[0m\n",
      "\u001b[34mEpoch 00037 | Time(s) 3.0369 | Loss 0.1040 | f1 0.7157\u001b[0m\n",
      "\u001b[34mEpoch 00038 | Time(s) 3.0350 | Loss 0.1028 | f1 0.7214\u001b[0m\n",
      "\u001b[34mEpoch 00039 | Time(s) 3.0327 | Loss 0.1018 | f1 0.7304\u001b[0m\n",
      "\u001b[34mEpoch 00040 | Time(s) 3.0309 | Loss 0.1008 | f1 0.7427\u001b[0m\n",
      "\u001b[34mEpoch 00041 | Time(s) 3.0289 | Loss 0.1001 | f1 0.7521\u001b[0m\n",
      "\u001b[34mEpoch 00042 | Time(s) 3.0275 | Loss 0.0992 | f1 0.7589\u001b[0m\n",
      "\u001b[34mEpoch 00043 | Time(s) 3.0260 | Loss 0.0974 | f1 0.7633\u001b[0m\n",
      "\u001b[34mEpoch 00044 | Time(s) 3.0240 | Loss 0.0956 | f1 0.7617\u001b[0m\n",
      "\u001b[34mEpoch 00045 | Time(s) 3.0228 | Loss 0.0953 | f1 0.7578\u001b[0m\n",
      "\u001b[34mEpoch 00046 | Time(s) 3.0302 | Loss 0.0952 | f1 0.7575\u001b[0m\n",
      "\u001b[34mEpoch 00047 | Time(s) 3.0290 | Loss 0.0938 | f1 0.7635\u001b[0m\n",
      "\u001b[34mEpoch 00048 | Time(s) 3.0271 | Loss 0.0918 | f1 0.7706\u001b[0m\n",
      "\u001b[34mEpoch 00049 | Time(s) 3.0254 | Loss 0.0909 | f1 0.7746\u001b[0m\n",
      "\u001b[34mEpoch 00050 | Time(s) 3.0236 | Loss 0.0908 | f1 0.7789\u001b[0m\n",
      "\u001b[34mEpoch 00051 | Time(s) 3.0222 | Loss 0.0901 | f1 0.7811\u001b[0m\n",
      "\u001b[34mEpoch 00052 | Time(s) 3.0206 | Loss 0.0883 | f1 0.7817\u001b[0m\n",
      "\u001b[34mEpoch 00053 | Time(s) 3.0191 | Loss 0.0872 | f1 0.7823\u001b[0m\n",
      "\u001b[34mEpoch 00054 | Time(s) 3.0182 | Loss 0.0871 | f1 0.7860\u001b[0m\n",
      "\u001b[34mEpoch 00055 | Time(s) 3.0169 | Loss 0.0863 | f1 0.7919\u001b[0m\n",
      "\u001b[34mEpoch 00056 | Time(s) 3.0155 | Loss 0.0847 | f1 0.7963\u001b[0m\n",
      "\u001b[34mEpoch 00057 | Time(s) 3.0154 | Loss 0.0839 | f1 0.7955\u001b[0m\n",
      "\u001b[34mEpoch 00058 | Time(s) 3.0145 | Loss 0.0835 | f1 0.7953\u001b[0m\n",
      "\u001b[34mEpoch 00059 | Time(s) 3.0134 | Loss 0.0824 | f1 0.7951\u001b[0m\n",
      "\u001b[34mEpoch 00060 | Time(s) 3.0123 | Loss 0.0815 | f1 0.7993\u001b[0m\n",
      "\u001b[34mEpoch 00061 | Time(s) 3.0110 | Loss 0.0808 | f1 0.8060\u001b[0m\n",
      "\u001b[34mEpoch 00062 | Time(s) 3.0122 | Loss 0.0799 | f1 0.8120\u001b[0m\n",
      "\u001b[34mEpoch 00063 | Time(s) 3.0113 | Loss 0.0792 | f1 0.8156\u001b[0m\n",
      "\u001b[34mEpoch 00064 | Time(s) 3.0098 | Loss 0.0783 | f1 0.8117\u001b[0m\n",
      "\u001b[34mEpoch 00065 | Time(s) 3.0086 | Loss 0.0774 | f1 0.8103\u001b[0m\n",
      "\u001b[34mEpoch 00066 | Time(s) 3.0077 | Loss 0.0768 | f1 0.8144\u001b[0m\n",
      "\u001b[34mEpoch 00067 | Time(s) 3.0069 | Loss 0.0758 | f1 0.8227\u001b[0m\n",
      "\u001b[34mEpoch 00068 | Time(s) 3.0063 | Loss 0.0749 | f1 0.8278\u001b[0m\n",
      "\u001b[34mEpoch 00069 | Time(s) 3.0053 | Loss 0.0743 | f1 0.8282\u001b[0m\n",
      "\u001b[34mEpoch 00070 | Time(s) 3.0043 | Loss 0.0733 | f1 0.8241\u001b[0m\n",
      "\u001b[34mEpoch 00071 | Time(s) 3.0036 | Loss 0.0725 | f1 0.8254\u001b[0m\n",
      "\u001b[34mEpoch 00072 | Time(s) 3.0027 | Loss 0.0717 | f1 0.8326\u001b[0m\n",
      "\u001b[34mEpoch 00073 | Time(s) 3.0020 | Loss 0.0708 | f1 0.8380\u001b[0m\n",
      "\u001b[34mEpoch 00074 | Time(s) 3.0013 | Loss 0.0700 | f1 0.8374\u001b[0m\n",
      "\u001b[34mEpoch 00075 | Time(s) 3.0006 | Loss 0.0692 | f1 0.8363\u001b[0m\n",
      "\u001b[34mEpoch 00076 | Time(s) 3.0004 | Loss 0.0683 | f1 0.8392\u001b[0m\n",
      "\u001b[34mEpoch 00077 | Time(s) 2.9996 | Loss 0.0675 | f1 0.8425\u001b[0m\n",
      "\u001b[34mEpoch 00078 | Time(s) 2.9999 | Loss 0.0667 | f1 0.8449\u001b[0m\n",
      "\u001b[34mEpoch 00079 | Time(s) 3.0032 | Loss 0.0658 | f1 0.8480\u001b[0m\n",
      "\u001b[34mEpoch 00080 | Time(s) 3.0027 | Loss 0.0651 | f1 0.8508\u001b[0m\n",
      "\u001b[34mEpoch 00081 | Time(s) 3.0020 | Loss 0.0642 | f1 0.8510\u001b[0m\n",
      "\u001b[34mEpoch 00082 | Time(s) 3.0011 | Loss 0.0634 | f1 0.8535\u001b[0m\n",
      "\u001b[34mEpoch 00083 | Time(s) 3.0010 | Loss 0.0626 | f1 0.8593\u001b[0m\n",
      "\u001b[34mEpoch 00084 | Time(s) 3.0004 | Loss 0.0618 | f1 0.8613\u001b[0m\n",
      "\u001b[34mEpoch 00085 | Time(s) 3.0008 | Loss 0.0610 | f1 0.8594\u001b[0m\n",
      "\u001b[34mEpoch 00086 | Time(s) 3.0002 | Loss 0.0602 | f1 0.8627\u001b[0m\n",
      "\u001b[34mEpoch 00087 | Time(s) 3.0001 | Loss 0.0594 | f1 0.8694\u001b[0m\n",
      "\u001b[34mEpoch 00088 | Time(s) 2.9997 | Loss 0.0587 | f1 0.8682\u001b[0m\n",
      "\u001b[34mEpoch 00089 | Time(s) 2.9994 | Loss 0.0579 | f1 0.8700\u001b[0m\n",
      "\u001b[34mEpoch 00090 | Time(s) 2.9989 | Loss 0.0571 | f1 0.8738\u001b[0m\n",
      "\u001b[34mEpoch 00091 | Time(s) 2.9985 | Loss 0.0563 | f1 0.8756\u001b[0m\n",
      "\u001b[34mEpoch 00092 | Time(s) 2.9981 | Loss 0.0556 | f1 0.8780\u001b[0m\n",
      "\u001b[34mEpoch 00093 | Time(s) 2.9973 | Loss 0.0548 | f1 0.8777\u001b[0m\n",
      "\u001b[34mEpoch 00094 | Time(s) 2.9971 | Loss 0.0540 | f1 0.8833\u001b[0m\n",
      "\u001b[34mEpoch 00095 | Time(s) 2.9985 | Loss 0.0532 | f1 0.8838\u001b[0m\n",
      "\u001b[34mEpoch 00096 | Time(s) 2.9981 | Loss 0.0524 | f1 0.8851\u001b[0m\n",
      "\u001b[34mEpoch 00097 | Time(s) 2.9979 | Loss 0.0517 | f1 0.8893\u001b[0m\n",
      "\u001b[34mEpoch 00098 | Time(s) 2.9974 | Loss 0.0509 | f1 0.8906\u001b[0m\n",
      "\u001b[34mEpoch 00099 | Time(s) 2.9969 | Loss 0.0501 | f1 0.8931\u001b[0m\n",
      "\u001b[34mEpoch 00100 | Time(s) 2.9968 | Loss 0.0493 | f1 0.8955\u001b[0m\n",
      "\u001b[34mEpoch 00101 | Time(s) 2.9969 | Loss 0.0485 | f1 0.8982\u001b[0m\n",
      "\u001b[34mEpoch 00102 | Time(s) 2.9965 | Loss 0.0476 | f1 0.8968\u001b[0m\n",
      "\u001b[34mEpoch 00103 | Time(s) 2.9961 | Loss 0.0470 | f1 0.9005\u001b[0m\n",
      "\u001b[34mEpoch 00104 | Time(s) 2.9958 | Loss 0.0477 | f1 0.8576\u001b[0m\n",
      "\u001b[34mEpoch 00105 | Time(s) 2.9958 | Loss 0.0583 | f1 0.8343\u001b[0m\n",
      "\u001b[34mEpoch 00106 | Time(s) 2.9955 | Loss 0.0718 | f1 0.8018\u001b[0m\n",
      "\u001b[34mEpoch 00107 | Time(s) 2.9952 | Loss 0.0906 | f1 0.8659\u001b[0m\n",
      "\u001b[34mEpoch 00108 | Time(s) 2.9952 | Loss 0.0611 | f1 0.8252\u001b[0m\n",
      "\u001b[34mEpoch 00109 | Time(s) 2.9945 | Loss 0.0788 | f1 0.8990\u001b[0m\n",
      "\u001b[34mEpoch 00110 | Time(s) 2.9941 | Loss 0.0478 | f1 0.8454\u001b[0m\n",
      "\u001b[34mEpoch 00111 | Time(s) 2.9971 | Loss 0.0633 | f1 0.8969\u001b[0m\n",
      "\u001b[34mEpoch 00112 | Time(s) 2.9969 | Loss 0.0442 | f1 0.8571\u001b[0m\n",
      "\u001b[34mEpoch 00113 | Time(s) 2.9965 | Loss 0.0660 | f1 0.8772\u001b[0m\n",
      "\u001b[34mEpoch 00114 | Time(s) 2.9962 | Loss 0.0505 | f1 0.8598\u001b[0m\n",
      "\u001b[34mEpoch 00115 | Time(s) 2.9957 | Loss 0.0631 | f1 0.9066\u001b[0m\n",
      "\u001b[34mEpoch 00116 | Time(s) 2.9952 | Loss 0.0457 | f1 0.8835\u001b[0m\n",
      "\u001b[34mEpoch 00117 | Time(s) 2.9948 | Loss 0.0513 | f1 0.9219\u001b[0m\n",
      "\u001b[34mEpoch 00118 | Time(s) 2.9944 | Loss 0.0401 | f1 0.9042\u001b[0m\n",
      "\u001b[34mEpoch 00119 | Time(s) 2.9940 | Loss 0.0401 | f1 0.8953\u001b[0m\n",
      "\u001b[34mEpoch 00120 | Time(s) 2.9936 | Loss 0.0415 | f1 0.9346\u001b[0m\n",
      "\u001b[34mEpoch 00121 | Time(s) 2.9932 | Loss 0.0349 | f1 0.9200\u001b[0m\n",
      "\u001b[34mEpoch 00122 | Time(s) 2.9928 | Loss 0.0400 | f1 0.9337\u001b[0m\n",
      "\u001b[34mEpoch 00123 | Time(s) 2.9924 | Loss 0.0334 | f1 0.9115\u001b[0m\n",
      "\u001b[34mEpoch 00124 | Time(s) 2.9922 | Loss 0.0358 | f1 0.9391\u001b[0m\n",
      "\u001b[34mEpoch 00125 | Time(s) 2.9919 | Loss 0.0314 | f1 0.9445\u001b[0m\n",
      "\u001b[34mEpoch 00126 | Time(s) 2.9914 | Loss 0.0303 | f1 0.9560\u001b[0m\n",
      "\u001b[34mEpoch 00127 | Time(s) 2.9943 | Loss 0.0286 | f1 0.9389\u001b[0m\n",
      "\u001b[34mEpoch 00128 | Time(s) 2.9943 | Loss 0.0285 | f1 0.9425\u001b[0m\n",
      "\u001b[34mEpoch 00129 | Time(s) 2.9939 | Loss 0.0287 | f1 0.9431\u001b[0m\n",
      "\u001b[34mEpoch 00130 | Time(s) 2.9936 | Loss 0.0275 | f1 0.9598\u001b[0m\n",
      "\u001b[34mEpoch 00131 | Time(s) 2.9933 | Loss 0.0265 | f1 0.9481\u001b[0m\n",
      "\u001b[34mEpoch 00132 | Time(s) 2.9930 | Loss 0.0254 | f1 0.9561\u001b[0m\n",
      "\u001b[34mEpoch 00133 | Time(s) 2.9929 | Loss 0.0241 | f1 0.9632\u001b[0m\n",
      "\u001b[34mEpoch 00134 | Time(s) 2.9925 | Loss 0.0218 | f1 0.9613\u001b[0m\n",
      "\u001b[34mEpoch 00135 | Time(s) 2.9923 | Loss 0.0221 | f1 0.9659\u001b[0m\n",
      "\u001b[34mEpoch 00136 | Time(s) 2.9920 | Loss 0.0222 | f1 0.9442\u001b[0m\n",
      "\u001b[34mEpoch 00137 | Time(s) 2.9916 | Loss 0.0255 | f1 0.9647\u001b[0m\n",
      "\u001b[34mEpoch 00138 | Time(s) 2.9913 | Loss 0.0223 | f1 0.9565\u001b[0m\n",
      "\u001b[34mEpoch 00139 | Time(s) 2.9906 | Loss 0.0228 | f1 0.9696\u001b[0m\n",
      "\u001b[34mEpoch 00140 | Time(s) 2.9902 | Loss 0.0193 | f1 0.9673\u001b[0m\n",
      "\u001b[34mEpoch 00141 | Time(s) 2.9902 | Loss 0.0196 | f1 0.9565\u001b[0m\n",
      "\u001b[34mEpoch 00142 | Time(s) 2.9898 | Loss 0.0217 | f1 0.9708\u001b[0m\n",
      "\u001b[34mEpoch 00143 | Time(s) 2.9913 | Loss 0.0199 | f1 0.9632\u001b[0m\n",
      "\u001b[34mEpoch 00144 | Time(s) 2.9913 | Loss 0.0194 | f1 0.9725\u001b[0m\n",
      "\u001b[34mEpoch 00145 | Time(s) 2.9916 | Loss 0.0175 | f1 0.9748\u001b[0m\n",
      "\u001b[34mEpoch 00146 | Time(s) 2.9913 | Loss 0.0170 | f1 0.9677\u001b[0m\n",
      "\u001b[34mEpoch 00147 | Time(s) 2.9910 | Loss 0.0182 | f1 0.9725\u001b[0m\n",
      "\u001b[34mEpoch 00148 | Time(s) 2.9907 | Loss 0.0182 | f1 0.9605\u001b[0m\n",
      "\n",
      "2023-01-25 17:54:37 Uploading - Uploading generated training model\u001b[34mEpoch 00149 | Time(s) 2.9904 | Loss 0.0198 | f1 0.9763\u001b[0m\n",
      "\u001b[34mFinished Model training\u001b[0m\n",
      "\u001b[34mSaving model to /opt/ml/model\u001b[0m\n",
      "\u001b[34m2023-01-25 12:54:33,813 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-01-25 12:54:33,813 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-01-25 12:54:33,814 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-01-25 17:58:48 Completed - Training job completed\n",
      "Training seconds: 1066\n",
      "Billable seconds: 1066\n"
     ]
    }
   ],
   "source": [
    "### fit SM estimator\n",
    "estimator.fit({\"training\": inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef0f834",
   "metadata": {},
   "source": [
    "# Deploy trained RGCN model to SageMaker endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b797c6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create sm model from model data + source code\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role=role,\n",
    "                     entry_point='smtrain.py', \n",
    "                     source_dir='fgnn',\n",
    "                     py_version=\"py38\",\n",
    "                     framework_version=\"1.11.0\",\n",
    "                     model_server_workers=2)\n",
    "\n",
    "## alternatively, use fitted estimator object to create sm model\n",
    "# model = estimator.create_model(model_server_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e582b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------!"
     ]
    }
   ],
   "source": [
    "## deploy sm model to an endpoint that will accept payload in (serialized) parquet format\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type=\"ml.m5.4xlarge\", \n",
    "                         serializer=IdentitySerializer(content_type='application/x-parquet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c0ceef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### alternatively, deploy sm model to an endpoint that will accept payload in CSV format\n",
    "# predictor_csv = model.deploy(initial_instance_count=1, instance_type=\"ml.m5.4xlarge\", \n",
    "#                              serializer=IdentitySerializer(content_type='text/csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455fa50b",
   "metadata": {},
   "source": [
    "# Invoke endpoint with test transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72f24e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load test transactions\n",
    "df_test = pd.read_parquet('./data/test.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "318c226e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### sample batch of 1000 transaction\n",
    "df_batch=df_test.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "85c03593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.5 ms, sys: 201 µs, total: 67.7 ms\n",
      "Wall time: 7.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### serialize parquet table with test transactions\n",
    "buffer = BytesIO()\n",
    "df_batch.drop(columns=['isFraud']).to_parquet(buffer)\n",
    "### invoke model endpoint with serialized parquet payload\n",
    "response = predictor.predict(buffer.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e19ec6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "### invoke model endpoint with CSV payload\n",
    "### note that using CSV format may result in prediction error because CSV serialization will loose column type information:\n",
    "### e.g., when all rows for a string/object column has NaN values in a batch, this column will be deserialized as type float on the endpoint side,\n",
    "###       and one-hot-encoding of this column will fail inside fraud_detector.py (line `self._cat_transformer.transform(test_transactions)`)\n",
    "#\n",
    "# response = predictor_csv.predict(df_batch.to_csv(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aa7af8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8737550277724574"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### compute roc-auc score for the batch\n",
    "roc_auc_score(df_batch.isFraud, response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218c6325",
   "metadata": {},
   "source": [
    "# Delete SageMaker endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca2a19d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session.delete_endpoint(endpoint_name=predictor.endpoint_name)\n",
    "# sagemaker_session.delete_endpoint(endpoint_name=predictor_csv.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f7aa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
